{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import chromadb\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import pgvector\n",
    "from pgvector.psycopg2 import register_vector\n",
    "import json\n",
    "import os\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to PostgreSQL database in Timescale using connection string\n",
    "conn = psycopg2.connect(\n",
    "    host=os.environ['HOST'],                        # e.g., \"localhost\"\n",
    "    database=os.environ['DATABASE'],                # your database name\n",
    "    user=os.environ['USER'],                        # your username\n",
    "    password=os.environ['PASSWD'],                  # your password   \n",
    "    port=os.environ['PORT']                         # the default port for PostgreSQL is 5432\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "#install pgvector\n",
    "cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector\");\n",
    "conn.commit()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the vector type with psycopg2\n",
    "register_vector(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table to store embeddings and metadata\n",
    "table_create_command = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS public.vector_store4 (\n",
    "            id uuid DEFAULT uuid_generate_v4() PRIMARY KEY,\n",
    "            content text,\n",
    "            metadata json,\n",
    "            embedding vector(768)\n",
    "            );\n",
    "            \"\"\"\n",
    "\n",
    "cur.execute(table_create_command)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create table to store embeddings and metadata\n",
    "# table_create_command = \"\"\"\n",
    "# DELETE FROM public.vector_store\n",
    "#             \"\"\"\n",
    "\n",
    "# cur.execute(table_create_command)\n",
    "# conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:    \n",
    "    select_query = \"\"\"\n",
    "    SELECT id, content, metadata, embedding\n",
    "    FROM public.vector_store4;\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute the query\n",
    "    cur.execute(select_query)\n",
    "\n",
    "    # Fetch all rows from the table\n",
    "    rows = cur.fetchall()\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Data from the vector_store table:\")\n",
    "    for row in rows:\n",
    "        print(f\"ID: {row[0]}\")\n",
    "        print(f\"Content: {row[1]}\")\n",
    "        print(f\"Metadata: {json.dumps(row[2], indent=2)}\")  # Pretty print the JSON metadata\n",
    "        print(f\"Embedding: {row[3][:10]}...\")  # Print the first 10 elements of the embedding (1536-dimensional vector)\n",
    "        print(\"=\"*50)\n",
    "\n",
    "except psycopg2.DatabaseError as error:\n",
    "    print(f\"Error occurred: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read CSV and Insert data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tcc_ceds_music.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmbedding(row):\n",
    "    # generate a response combining the prompt and data we retrieved in step 2\n",
    "    summarize_lyrics = ollama.generate(\n",
    "        model=\"llama3.1\",\n",
    "        # prompt=f\"This is the prompt from the user: {data}. Respond using this information: {json.dumps(data_from_db)}. Only use the book from the database to answer.\",\n",
    "        prompt=f\"\"\"\n",
    "        Summarize this random word using under 100 words: {str(row[\"lyrics\"])}. \n",
    "\n",
    "        Do not write \"Here's a summary\", only write the content.\n",
    "        \"\"\"\n",
    "    )\n",
    "    print(summarize_lyrics['response'])\n",
    "\n",
    "    data = {\n",
    "        # \"content\": str(row[\"lyrics\"]),\n",
    "        \"content\": summarize_lyrics['response'],\n",
    "        \"metadata\": {\n",
    "                \"artist_name\": row[\"artist_name\"],\n",
    "                \"track_name\": row[\"track_name\"],\n",
    "                \"release_date\": str(row[\"release_date\"]),\n",
    "                \"len\": str(row[\"len\"]),\n",
    "                \"genre\": row[\"genre\"],\n",
    "                \"topic\": row[\"topic\"]\n",
    "                }\n",
    "    } \n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    This is the metadata of the music: {json.dumps(data[\"metadata\"])}\n",
    "    \n",
    "    This is the lyrics of the music: {data[\"content\"]}\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # print(prompt)\n",
    "    # meta_embedding = ollama.embeddings(\n",
    "    #     prompt=json.dumps(json.dumps(data[\"metadata\"])),\n",
    "    #     model=\"nomic-embed-text\",\n",
    "    #     options={\"num_ctx\": 8192}\n",
    "    # )\n",
    "    embedding = ollama.embeddings(\n",
    "        prompt=prompt,\n",
    "        model=\"nomic-embed-text\",\n",
    "        options={\"num_ctx\": 8192}\n",
    "    )\n",
    "    # embedding size 768\n",
    "    return embedding[\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addData2Table(index, cur, conn, row, collection, is_add_to_table=True):\n",
    "    data = {\n",
    "        \"content\": str(row[\"lyrics\"]),\n",
    "        \"metadata\": {\n",
    "                \"track_name\": row[\"track_name\"],\n",
    "                \"artist_name\": row[\"artist_name\"],\n",
    "                \"release_date\": str(row[\"release_date\"]),\n",
    "                \"len\": str(row[\"len\"]),\n",
    "                \"genre\": row[\"genre\"],\n",
    "                \"topic\": row[\"topic\"],\n",
    "                },\n",
    "        \"embedding\": getEmbedding(row)\n",
    "    }\n",
    "    # cur.execute(\"SELECT 1 FROM public.vector_store4 WHERE content = %s;\", (data[\"content\"],))\n",
    "    # exists = cur.fetchone()\n",
    "    # conn.commit()\n",
    "\n",
    "    # if exists:\n",
    "    \n",
    "    \n",
    "    if is_add_to_table:\n",
    "        insert_query = \"\"\"\n",
    "            INSERT INTO public.vector_store4 (content, metadata, embedding)\n",
    "            VALUES (%s, %s, %s::vector);\n",
    "        \"\"\"\n",
    "\n",
    "        # Execute the query with provided values\n",
    "        cur.execute(insert_query, (data[\"content\"], json.dumps(data[\"metadata\"]), data[\"embedding\"]))\n",
    "        conn.commit()\n",
    "    else:\n",
    "        collection.add(\n",
    "            ids=[str(index)],\n",
    "            embeddings=[data[\"embedding\"]],\n",
    "            metadatas=[data[\"metadata\"]],\n",
    "            documents=[str(row[\"lyrics\"])]\n",
    "        )\n",
    "    # else:\n",
    "        # print(\"The song already exist: {}\".format(data[\"metadata\"][\"track_name\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.Client()\n",
    "# client.delete_collection(name=\"docs\")\n",
    "collection = client.create_collection(name=\"docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        addData2Table(index, cur, conn, row, collection ,is_add_to_table=True)\n",
    "        print(\"{} Successfully add new song: {}\".format(index, row[\"track_name\"]))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"failed to add {}\".format(row[\"track_name\"]))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get all data from the collection\n",
    "# chromadb_results = collection.get()\n",
    "\n",
    "# # Export to JSON file\n",
    "# with open('collection_data.json', 'w') as file:\n",
    "#     json.dump(chromadb_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example prompt\n",
    "prompt = \"Can you find the author and the release date of the song name 'dear heart'?\"\n",
    "\n",
    "# generate an embedding for the prompt and retrieve the most relevant doc\n",
    "response = ollama.embeddings(\n",
    "    prompt=prompt,\n",
    "    model=\"nomic-embed-text\"\n",
    ")\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=response[\"embedding\"],\n",
    "    n_results=2\n",
    ")\n",
    "data_from_db = results\n",
    "# print(len(data_from_db))\n",
    "print(results[\"documents\"][0])\n",
    "# print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"metadatas\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a response combining the prompt and data we retrieved in step 2\n",
    "filter_prompt = ollama.generate(\n",
    "    model=\"llama3.1\",\n",
    "    prompt=f\"\"\"\n",
    "    This is the user question: {prompt}\n",
    "    \n",
    "    Can you find the information from only this field in database: \"track_name\", \"artist_name\", \"release_date\", \"len\", \"genre\"\n",
    "    \n",
    "    Strictly answer either \"YES\" or \"NO\". If yes you need to specify the field that you can find this information. If the song is not exist, you must answer \"NO\". \n",
    "    \"\"\"\n",
    ")\n",
    "print(filter_prompt['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a response combining the prompt and data we retrieved in step 2\n",
    "filter_prompt = ollama.generate(\n",
    "    model=\"llama3.1\",\n",
    "    prompt=f\"\"\"\n",
    "        From the list of metadata of 2 songs: {results[\"metadatas\"][0]}\n",
    "\n",
    "        Can you answer this question: {prompt}\n",
    "\n",
    "        You must only choose the information from only one song from the list of metadata. \n",
    "        Do not mention the word \"metadata\" when answer the question, but you can use other key words from the list of metadata. Do not hallucinate.\n",
    "    \"\"\"\n",
    ")\n",
    "print(filter_prompt['response'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a response combining the prompt and data we retrieved in step 2\n",
    "summarize_lyrics1 = ollama.generate(\n",
    "    model=\"llama3.1\",\n",
    "    # prompt=f\"This is the prompt from the user: {data}. Respond using this information: {json.dumps(data_from_db)}. Only use the book from the database to answer.\",\n",
    "    prompt=f\"\"\"\n",
    "    Summarize this random word using under 100 words: {results[\"documents\"][0][0]}. \n",
    "    \n",
    "    Do not write \"Here's a summary\", only write the content.\n",
    "    \"\"\"\n",
    ")\n",
    "print(summarize_lyrics1['response'])\n",
    "\n",
    "# summarize_lyrics2 = ollama.generate(\n",
    "#     model=\"llama3.1\",\n",
    "#     # prompt=f\"This is the prompt from the user: {data}. Respond using this information: {json.dumps(data_from_db)}. Only use the book from the database to answer.\",\n",
    "#     prompt=f\"\"\"\n",
    "#     Summarize this random word: {results[\"documents\"][0][1]}. \n",
    "    \n",
    "#     Do not write \"Here's a summary\", only write the content.\n",
    "#     \"\"\"\n",
    "# )\n",
    "# print(summarize_lyrics2['response'])\n",
    "\n",
    "# summarize_selection = ollama.generate(\n",
    "#     model=\"llama3.1\",\n",
    "#     # prompt=f\"This is the prompt from the user: {data}. Respond using this information: {json.dumps(data_from_db)}. Only use the book from the database to answer.\",\n",
    "#     prompt=f\"\"\"\n",
    "#     This is the user question: {prompt}\n",
    "\n",
    "#     This is the meta data information from the song '{results[\"metadatas\"][0][0][\"track_name\"]}': {json.dumps(results[\"metadatas\"][0][0])}\n",
    "    \n",
    "#     This is the lyrics of the song '{results[\"metadatas\"][0][0][\"track_name\"]}: {results[\"documents\"][0][0]}\n",
    "\n",
    "\n",
    "#     This is the meta data information of the song '{results[\"metadatas\"][0][1][\"track_name\"]}: {json.dumps(results[\"metadatas\"][0][1])}\n",
    "\n",
    "#     This is the lyrics of the song '{results[\"metadatas\"][0][1][\"track_name\"]}: {results[\"documents\"][0][1]}\n",
    "\n",
    "#     Answer the user question by selecting either information from '{results[\"metadatas\"][0][0][\"track_name\"]}' or '{results[\"metadatas\"][0][1][\"track_name\"]}' that are more closely relate to the user question. Why you select this song? \n",
    "#     If you think that both song are not related to user question. You must say that there is no song in the database that match the user description. \n",
    "#     Do not make up information. Do not mention the another song in the output. Do not use the sentence that means 'Based on the user's question' when answer. Do not mention the word that means summary.\n",
    "#     \"\"\"\n",
    "# )\n",
    "# print(\"__________________\")\n",
    "# print(summarize_selection['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Close the cursor and connection\n",
    "# cur.close()\n",
    "# conn.close()\n",
    "\n",
    "# print(\"Data inserted successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
