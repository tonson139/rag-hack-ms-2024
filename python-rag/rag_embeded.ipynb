{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import chromadb\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import pgvector\n",
    "from pgvector.psycopg2 import register_vector\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to PostgreSQL database in Timescale using connection string\n",
    "conn = psycopg2.connect(\n",
    "    host=\"aws-0-ap-southeast-1.pooler.supabase.com\",        # e.g., \"localhost\"\n",
    "    database=\"postgres\",                                    # your database name\n",
    "    user=\"postgres.dqdozshjpydgkstvjspa\",                   # your username\n",
    "    password=\"n7x6zPFv2BKa00jg\",                            # your password\n",
    "    port=\"6543\"                                             # the default port for PostgreSQL is 5432\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "#install pgvector\n",
    "cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector\");\n",
    "conn.commit()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the vector type with psycopg2\n",
    "register_vector(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table to store embeddings and metadata\n",
    "table_create_command = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS public.vector_store4 (\n",
    "            id uuid DEFAULT uuid_generate_v4() PRIMARY KEY,\n",
    "            content text,\n",
    "            metadata json,\n",
    "            embedding vector(768)\n",
    "            );\n",
    "            \"\"\"\n",
    "\n",
    "cur.execute(table_create_command)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create table to store embeddings and metadata\n",
    "# table_create_command = \"\"\"\n",
    "# DELETE FROM public.vector_store\n",
    "#             \"\"\"\n",
    "\n",
    "# cur.execute(table_create_command)\n",
    "# conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from the vector_store table:\n"
     ]
    }
   ],
   "source": [
    "try:    \n",
    "    select_query = \"\"\"\n",
    "    SELECT id, content, metadata, embedding\n",
    "    FROM public.vector_store4;\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute the query\n",
    "    cur.execute(select_query)\n",
    "\n",
    "    # Fetch all rows from the table\n",
    "    rows = cur.fetchall()\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Data from the vector_store table:\")\n",
    "    for row in rows:\n",
    "        print(f\"ID: {row[0]}\")\n",
    "        print(f\"Content: {row[1]}\")\n",
    "        print(f\"Metadata: {json.dumps(row[2], indent=2)}\")  # Pretty print the JSON metadata\n",
    "        print(f\"Embedding: {row[3][:10]}...\")  # Print the first 10 elements of the embedding (1536-dimensional vector)\n",
    "        print(\"=\"*50)\n",
    "\n",
    "except psycopg2.DatabaseError as error:\n",
    "    print(f\"Error occurred: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read CSV and Insert data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>release_date</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>len</th>\n",
       "      <th>dating</th>\n",
       "      <th>violence</th>\n",
       "      <th>world/life</th>\n",
       "      <th>...</th>\n",
       "      <th>sadness</th>\n",
       "      <th>feelings</th>\n",
       "      <th>danceability</th>\n",
       "      <th>loudness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>valence</th>\n",
       "      <th>energy</th>\n",
       "      <th>topic</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mukesh</td>\n",
       "      <td>mohabbat bhi jhoothi</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>hold time feel break feel untrue convince spea...</td>\n",
       "      <td>95</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.063746</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380299</td>\n",
       "      <td>0.117175</td>\n",
       "      <td>0.357739</td>\n",
       "      <td>0.454119</td>\n",
       "      <td>0.997992</td>\n",
       "      <td>0.901822</td>\n",
       "      <td>0.339448</td>\n",
       "      <td>0.137110</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>frankie laine</td>\n",
       "      <td>i believe</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>believe drop rain fall grow believe darkest ni...</td>\n",
       "      <td>51</td>\n",
       "      <td>0.035537</td>\n",
       "      <td>0.096777</td>\n",
       "      <td>0.443435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.331745</td>\n",
       "      <td>0.647540</td>\n",
       "      <td>0.954819</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.325021</td>\n",
       "      <td>0.263240</td>\n",
       "      <td>world/life</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>johnnie ray</td>\n",
       "      <td>cry</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>sweetheart send letter goodbye secret feel bet...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.225422</td>\n",
       "      <td>0.456298</td>\n",
       "      <td>0.585288</td>\n",
       "      <td>0.840361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.351814</td>\n",
       "      <td>0.139112</td>\n",
       "      <td>music</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>p√©rez prado</td>\n",
       "      <td>patricia</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>kiss lips want stroll charm mambo chacha merin...</td>\n",
       "      <td>54</td>\n",
       "      <td>0.048249</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225889</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.686992</td>\n",
       "      <td>0.744404</td>\n",
       "      <td>0.083935</td>\n",
       "      <td>0.199393</td>\n",
       "      <td>0.775350</td>\n",
       "      <td>0.743736</td>\n",
       "      <td>romantic</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>giorgos papadopoulos</td>\n",
       "      <td>apopse eida oneiro</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>till darling till matter know till dream live ...</td>\n",
       "      <td>48</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.417772</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.291671</td>\n",
       "      <td>0.646489</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.597073</td>\n",
       "      <td>0.394375</td>\n",
       "      <td>romantic</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28367</th>\n",
       "      <td>82447</td>\n",
       "      <td>mack 10</td>\n",
       "      <td>10 million ways</td>\n",
       "      <td>2019</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>cause fuck leave scar tick tock clock come kno...</td>\n",
       "      <td>78</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065664</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.889527</td>\n",
       "      <td>0.759711</td>\n",
       "      <td>0.062549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.751649</td>\n",
       "      <td>0.695686</td>\n",
       "      <td>obscene</td>\n",
       "      <td>0.014286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28368</th>\n",
       "      <td>82448</td>\n",
       "      <td>m.o.p.</td>\n",
       "      <td>ante up (robbin hoodz theory)</td>\n",
       "      <td>2019</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>minks things chain ring braclets yap fame come...</td>\n",
       "      <td>67</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.035338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.662082</td>\n",
       "      <td>0.789580</td>\n",
       "      <td>0.004607</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.922712</td>\n",
       "      <td>0.797791</td>\n",
       "      <td>obscene</td>\n",
       "      <td>0.014286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28369</th>\n",
       "      <td>82449</td>\n",
       "      <td>nine</td>\n",
       "      <td>whutcha want?</td>\n",
       "      <td>2019</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>get ban get ban stick crack relax plan attack ...</td>\n",
       "      <td>77</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>0.154302</td>\n",
       "      <td>0.168988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>0.663165</td>\n",
       "      <td>0.726970</td>\n",
       "      <td>0.104417</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.838211</td>\n",
       "      <td>0.767761</td>\n",
       "      <td>obscene</td>\n",
       "      <td>0.014286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28370</th>\n",
       "      <td>82450</td>\n",
       "      <td>will smith</td>\n",
       "      <td>switch</td>\n",
       "      <td>2019</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>check check yeah yeah hear thing call switch g...</td>\n",
       "      <td>67</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.883028</td>\n",
       "      <td>0.786888</td>\n",
       "      <td>0.007027</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.508450</td>\n",
       "      <td>0.885882</td>\n",
       "      <td>obscene</td>\n",
       "      <td>0.014286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28371</th>\n",
       "      <td>82451</td>\n",
       "      <td>jeezy</td>\n",
       "      <td>r.i.p.</td>\n",
       "      <td>2019</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>remix killer alive remix thriller trap bitch s...</td>\n",
       "      <td>83</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>0.033995</td>\n",
       "      <td>0.828875</td>\n",
       "      <td>0.674794</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.475474</td>\n",
       "      <td>0.492477</td>\n",
       "      <td>obscene</td>\n",
       "      <td>0.014286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28372 rows √ó 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0           artist_name                     track_name  \\\n",
       "0               0                mukesh           mohabbat bhi jhoothi   \n",
       "1               4         frankie laine                      i believe   \n",
       "2               6           johnnie ray                            cry   \n",
       "3              10           p√©rez prado                       patricia   \n",
       "4              12  giorgos papadopoulos             apopse eida oneiro   \n",
       "...           ...                   ...                            ...   \n",
       "28367       82447               mack 10                10 million ways   \n",
       "28368       82448                m.o.p.  ante up (robbin hoodz theory)   \n",
       "28369       82449                  nine                  whutcha want?   \n",
       "28370       82450            will smith                         switch   \n",
       "28371       82451                 jeezy                         r.i.p.   \n",
       "\n",
       "       release_date    genre  \\\n",
       "0              1950      pop   \n",
       "1              1950      pop   \n",
       "2              1950      pop   \n",
       "3              1950      pop   \n",
       "4              1950      pop   \n",
       "...             ...      ...   \n",
       "28367          2019  hip hop   \n",
       "28368          2019  hip hop   \n",
       "28369          2019  hip hop   \n",
       "28370          2019  hip hop   \n",
       "28371          2019  hip hop   \n",
       "\n",
       "                                                  lyrics  len    dating  \\\n",
       "0      hold time feel break feel untrue convince spea...   95  0.000598   \n",
       "1      believe drop rain fall grow believe darkest ni...   51  0.035537   \n",
       "2      sweetheart send letter goodbye secret feel bet...   24  0.002770   \n",
       "3      kiss lips want stroll charm mambo chacha merin...   54  0.048249   \n",
       "4      till darling till matter know till dream live ...   48  0.001350   \n",
       "...                                                  ...  ...       ...   \n",
       "28367  cause fuck leave scar tick tock clock come kno...   78  0.001350   \n",
       "28368  minks things chain ring braclets yap fame come...   67  0.001284   \n",
       "28369  get ban get ban stick crack relax plan attack ...   77  0.001504   \n",
       "28370  check check yeah yeah hear thing call switch g...   67  0.001196   \n",
       "28371  remix killer alive remix thriller trap bitch s...   83  0.001012   \n",
       "\n",
       "       violence  world/life  ...   sadness  feelings  danceability  loudness  \\\n",
       "0      0.063746    0.000598  ...  0.380299  0.117175      0.357739  0.454119   \n",
       "1      0.096777    0.443435  ...  0.001284  0.001284      0.331745  0.647540   \n",
       "2      0.002770    0.002770  ...  0.002770  0.225422      0.456298  0.585288   \n",
       "3      0.001548    0.001548  ...  0.225889  0.001548      0.686992  0.744404   \n",
       "4      0.001350    0.417772  ...  0.068800  0.001350      0.291671  0.646489   \n",
       "...         ...         ...  ...       ...       ...           ...       ...   \n",
       "28367  0.001350    0.001350  ...  0.065664  0.001350      0.889527  0.759711   \n",
       "28368  0.001284    0.035338  ...  0.001284  0.001284      0.662082  0.789580   \n",
       "28369  0.154302    0.168988  ...  0.001504  0.001504      0.663165  0.726970   \n",
       "28370  0.001196    0.001196  ...  0.001196  0.001196      0.883028  0.786888   \n",
       "28371  0.075202    0.001012  ...  0.001012  0.033995      0.828875  0.674794   \n",
       "\n",
       "       acousticness  instrumentalness   valence    energy       topic  \\\n",
       "0          0.997992          0.901822  0.339448  0.137110     sadness   \n",
       "1          0.954819          0.000002  0.325021  0.263240  world/life   \n",
       "2          0.840361          0.000000  0.351814  0.139112       music   \n",
       "3          0.083935          0.199393  0.775350  0.743736    romantic   \n",
       "4          0.975904          0.000246  0.597073  0.394375    romantic   \n",
       "...             ...               ...       ...       ...         ...   \n",
       "28367      0.062549          0.000000  0.751649  0.695686     obscene   \n",
       "28368      0.004607          0.000002  0.922712  0.797791     obscene   \n",
       "28369      0.104417          0.000001  0.838211  0.767761     obscene   \n",
       "28370      0.007027          0.000503  0.508450  0.885882     obscene   \n",
       "28371      0.015862          0.000000  0.475474  0.492477     obscene   \n",
       "\n",
       "            age  \n",
       "0      1.000000  \n",
       "1      1.000000  \n",
       "2      1.000000  \n",
       "3      1.000000  \n",
       "4      1.000000  \n",
       "...         ...  \n",
       "28367  0.014286  \n",
       "28368  0.014286  \n",
       "28369  0.014286  \n",
       "28370  0.014286  \n",
       "28371  0.014286  \n",
       "\n",
       "[28372 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('tcc_ceds_music.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'artist_name', 'track_name', 'release_date', 'genre',\n",
       "       'lyrics', 'len', 'dating', 'violence', 'world/life', 'night/time',\n",
       "       'shake the audience', 'family/gospel', 'romantic', 'communication',\n",
       "       'obscene', 'music', 'movement/places', 'light/visual perceptions',\n",
       "       'family/spiritual', 'like/girls', 'sadness', 'feelings', 'danceability',\n",
       "       'loudness', 'acousticness', 'instrumentalness', 'valence', 'energy',\n",
       "       'topic', 'age'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmbedding(row):\n",
    "    # generate a response combining the prompt and data we retrieved in step 2\n",
    "    summarize_lyrics = ollama.generate(\n",
    "        model=\"llama3.1\",\n",
    "        # prompt=f\"This is the prompt from the user: {data}. Respond using this information: {json.dumps(data_from_db)}. Only use the book from the database to answer.\",\n",
    "        prompt=f\"\"\"\n",
    "        Summarize this random word using under 100 words: {str(row[\"lyrics\"])}. \n",
    "\n",
    "        Do not write \"Here's a summary\", only write the content.\n",
    "        \"\"\"\n",
    "    )\n",
    "    print(summarize_lyrics['response'])\n",
    "\n",
    "    data = {\n",
    "        # \"content\": str(row[\"lyrics\"]),\n",
    "        \"content\": summarize_lyrics['response'],\n",
    "        \"metadata\": {\n",
    "                \"artist_name\": row[\"artist_name\"],\n",
    "                \"track_name\": row[\"track_name\"],\n",
    "                \"release_date\": str(row[\"release_date\"]),\n",
    "                \"len\": str(row[\"len\"]),\n",
    "                \"genre\": row[\"genre\"],\n",
    "                \"topic\": row[\"topic\"]\n",
    "                }\n",
    "    } \n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    This is the metadata of the music: {json.dumps(data[\"metadata\"])}\n",
    "    \n",
    "    This is the lyrics of the music: {data[\"content\"]}\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # print(prompt)\n",
    "    # meta_embedding = ollama.embeddings(\n",
    "    #     prompt=json.dumps(json.dumps(data[\"metadata\"])),\n",
    "    #     model=\"nomic-embed-text\",\n",
    "    #     options={\"num_ctx\": 8192}\n",
    "    # )\n",
    "    embedding = ollama.embeddings(\n",
    "        prompt=prompt,\n",
    "        model=\"nomic-embed-text\",\n",
    "        options={\"num_ctx\": 8192}\n",
    "    )\n",
    "    # embedding size 768\n",
    "    return embedding[\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addData2Table(index, cur, conn, row, collection, is_add_to_table=True):\n",
    "    data = {\n",
    "        \"content\": str(row[\"lyrics\"]),\n",
    "        \"metadata\": {\n",
    "                \"track_name\": row[\"track_name\"],\n",
    "                \"artist_name\": row[\"artist_name\"],\n",
    "                \"release_date\": str(row[\"release_date\"]),\n",
    "                \"len\": str(row[\"len\"]),\n",
    "                \"genre\": row[\"genre\"],\n",
    "                \"topic\": row[\"topic\"],\n",
    "                },\n",
    "        \"embedding\": getEmbedding(row)\n",
    "    }\n",
    "    # cur.execute(\"SELECT 1 FROM public.vector_store4 WHERE content = %s;\", (data[\"content\"],))\n",
    "    # exists = cur.fetchone()\n",
    "    # conn.commit()\n",
    "\n",
    "    # if exists:\n",
    "    \n",
    "    \n",
    "    if is_add_to_table:\n",
    "        insert_query = \"\"\"\n",
    "            INSERT INTO public.vector_store4 (content, metadata, embedding)\n",
    "            VALUES (%s, %s, %s::vector);\n",
    "        \"\"\"\n",
    "\n",
    "        # Execute the query with provided values\n",
    "        cur.execute(insert_query, (data[\"content\"], json.dumps(data[\"metadata\"]), data[\"embedding\"]))\n",
    "        conn.commit()\n",
    "    else:\n",
    "        collection.add(\n",
    "            ids=[str(index)],\n",
    "            embeddings=[data[\"embedding\"]],\n",
    "            metadatas=[data[\"metadata\"]],\n",
    "            documents=[str(row[\"lyrics\"])]\n",
    "        )\n",
    "    # else:\n",
    "        # print(\"The song already exist: {}\".format(data[\"metadata\"][\"track_name\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "UniqueConstraintError",
     "evalue": "Collection docs already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUniqueConstraintError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m client \u001b[38;5;241m=\u001b[39m chromadb\u001b[38;5;241m.\u001b[39mClient()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# client.delete_collection(name=\"docs\")\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m collection \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdocs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\worac\\anaconda3\\envs\\rag\\Lib\\site-packages\\chromadb\\api\\client.py:117\u001b[0m, in \u001b[0;36mClient.create_collection\u001b[1;34m(self, name, configuration, metadata, embedding_function, data_loader, get_or_create)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_collection\u001b[39m(\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    115\u001b[0m     get_or_create: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    116\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Collection:\n\u001b[1;32m--> 117\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_server\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfiguration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Collection(\n\u001b[0;32m    126\u001b[0m         client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_server,\n\u001b[0;32m    127\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    128\u001b[0m         embedding_function\u001b[38;5;241m=\u001b[39membedding_function,\n\u001b[0;32m    129\u001b[0m         data_loader\u001b[38;5;241m=\u001b[39mdata_loader,\n\u001b[0;32m    130\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\worac\\anaconda3\\envs\\rag\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py:146\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\worac\\anaconda3\\envs\\rag\\Lib\\site-packages\\chromadb\\api\\segment.py:176\u001b[0m, in \u001b[0;36mSegmentAPI.create_collection\u001b[1;34m(self, name, configuration, metadata, get_or_create, tenant, database)\u001b[0m\n\u001b[0;32m    164\u001b[0m model \u001b[38;5;241m=\u001b[39m CollectionModel(\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mid\u001b[39m,\n\u001b[0;32m    166\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    173\u001b[0m     dimension\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    174\u001b[0m )\n\u001b[0;32m    175\u001b[0m \u001b[38;5;66;03m# TODO: Let sysdb create the collection directly from the model\u001b[39;00m\n\u001b[1;32m--> 176\u001b[0m coll, created \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sysdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_configuration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdimension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# This is lazily populated on the first add\u001b[39;49;00m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m# TODO: wrap sysdb call in try except and log error if it fails\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created:\n",
      "File \u001b[1;32mc:\\Users\\worac\\anaconda3\\envs\\rag\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py:146\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\worac\\anaconda3\\envs\\rag\\Lib\\site-packages\\chromadb\\db\\mixins\\sysdb.py:229\u001b[0m, in \u001b[0;36mSqlSysDB.create_collection\u001b[1;34m(self, id, name, configuration, metadata, dimension, get_or_create, tenant, database)\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    223\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_collections(\n\u001b[0;32m    224\u001b[0m                 \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mcollection[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m], tenant\u001b[38;5;241m=\u001b[39mtenant, database\u001b[38;5;241m=\u001b[39mdatabase\n\u001b[0;32m    225\u001b[0m             )[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    226\u001b[0m             \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    227\u001b[0m         )\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 229\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m UniqueConstraintError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCollection \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m already exists\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    231\u001b[0m collection \u001b[38;5;241m=\u001b[39m Collection(\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mid\u001b[39m,\n\u001b[0;32m    233\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    239\u001b[0m     version\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    240\u001b[0m )\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtx() \u001b[38;5;28;01mas\u001b[39;00m cur:\n",
      "\u001b[1;31mUniqueConstraintError\u001b[0m: Collection docs already exists"
     ]
    }
   ],
   "source": [
    "client = chromadb.Client()\n",
    "# client.delete_collection(name=\"docs\")\n",
    "collection = client.create_collection(name=\"docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 11001] getaddrinfo failed\n",
      "failed to add mohabbat bhi jhoothi\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        addData2Table(index, cur, conn, row, collection ,is_add_to_table=True)\n",
    "        print(\"{} Successfully add new song: {}\".format(index, row[\"track_name\"]))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"failed to add {}\".format(row[\"track_name\"]))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get all data from the collection\n",
    "# chromadb_results = collection.get()\n",
    "\n",
    "# # Export to JSON file\n",
    "# with open('collection_data.json', 'w') as file:\n",
    "#     json.dump(chromadb_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dear heart wish warm night dear heart like year sight single room table lonesome right soon kiss hello door dear heart want know leave arm single room table lonesome right soon kiss hello door dear heart want know leave arm', 'night mind deep dream till time look eye touch soul hard hide apart feel heart know lock door throw away save save night dream belong hold feel right heart lock door throw away save save night save save turn know come baby stay save save turn need save save save save save baby save save']\n"
     ]
    }
   ],
   "source": [
    "# an example prompt\n",
    "prompt = \"Can you find the author and the release date of the song name 'dear heart'?\"\n",
    "\n",
    "# generate an embedding for the prompt and retrieve the most relevant doc\n",
    "response = ollama.embeddings(\n",
    "    prompt=prompt,\n",
    "    model=\"nomic-embed-text\"\n",
    ")\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=response[\"embedding\"],\n",
    "    n_results=2\n",
    ")\n",
    "data_from_db = results\n",
    "# print(len(data_from_db))\n",
    "print(results[\"documents\"][0])\n",
    "# print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'artist_name': 'andy williams',\n",
       "  'genre': 'pop',\n",
       "  'len': '40',\n",
       "  'release_date': '1957',\n",
       "  'topic': 'romantic',\n",
       "  'track_name': 'dear heart'},\n",
       " {'artist_name': 'los hermanos arriagada',\n",
       "  'genre': 'pop',\n",
       "  'len': '55',\n",
       "  'release_date': '1954',\n",
       "  'topic': 'sadness',\n",
       "  'track_name': 'poema'}]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"metadatas\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the given fields in the database, I can try to search for the song \"Just My Imagination\".\n",
      "\n",
      "Unfortunately, I couldn't find any information about the song \"Just My Imagination\" in the specified fields. However, this is not a guarantee that it doesn't exist, just that the fields provided don't have enough data.\n",
      "\n",
      "My answer would be:\n",
      "\n",
      "NO\n"
     ]
    }
   ],
   "source": [
    "# generate a response combining the prompt and data we retrieved in step 2\n",
    "filter_prompt = ollama.generate(\n",
    "    model=\"llama3.1\",\n",
    "    prompt=f\"\"\"\n",
    "    This is the user question: {prompt}\n",
    "    \n",
    "    Can you find the information from only this field in database: \"track_name\", \"artist_name\", \"release_date\", \"len\", \"genre\"\n",
    "    \n",
    "    Strictly answer either \"YES\" or \"NO\". If yes you need to specify the field that you can find this information. If the song is not exist, you must answer \"NO\". \n",
    "    \"\"\"\n",
    ")\n",
    "print(filter_prompt['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find the author and release date of the song 'just my imagination', I will look at the information provided for that specific song.\n",
      "\n",
      "The artist name of 'just my imagination (running away with me)' is pete yorn, which can be considered as the author of the song. \n",
      "\n",
      "As for the release date, it's stated as 1956.\n"
     ]
    }
   ],
   "source": [
    "# generate a response combining the prompt and data we retrieved in step 2\n",
    "filter_prompt = ollama.generate(\n",
    "    model=\"llama3.1\",\n",
    "    prompt=f\"\"\"\n",
    "        From the list of metadata of 2 songs: {results[\"metadatas\"][0]}\n",
    "\n",
    "        Can you answer this question: {prompt}\n",
    "\n",
    "        You must only choose the information from only one song from the list of metadata. \n",
    "        Do not mention the word \"metadata\" when answer the question, but you can use other key words from the list of metadata. Do not hallucinate.\n",
    "    \"\"\"\n",
    ")\n",
    "print(filter_prompt['response'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The repetition of phrases suggests a sense of nostalgia and longing, evoking a cozy atmosphere often associated with the concept of \"home\". The mention of birds implies a connection to nature, which contrasts with the solitude and isolation hinted at by words like \"single\" and \"solitary\". The overall tone is melancholic, suggesting a yearning for companionship and safety.\n"
     ]
    }
   ],
   "source": [
    "# generate a response combining the prompt and data we retrieved in step 2\n",
    "summarize_lyrics1 = ollama.generate(\n",
    "    model=\"llama3.1\",\n",
    "    # prompt=f\"This is the prompt from the user: {data}. Respond using this information: {json.dumps(data_from_db)}. Only use the book from the database to answer.\",\n",
    "    prompt=f\"\"\"\n",
    "    Summarize this random word using under 100 words: {results[\"documents\"][0][0]}. \n",
    "    \n",
    "    Do not write \"Here's a summary\", only write the content.\n",
    "    \"\"\"\n",
    ")\n",
    "print(summarize_lyrics1['response'])\n",
    "\n",
    "# summarize_lyrics2 = ollama.generate(\n",
    "#     model=\"llama3.1\",\n",
    "#     # prompt=f\"This is the prompt from the user: {data}. Respond using this information: {json.dumps(data_from_db)}. Only use the book from the database to answer.\",\n",
    "#     prompt=f\"\"\"\n",
    "#     Summarize this random word: {results[\"documents\"][0][1]}. \n",
    "    \n",
    "#     Do not write \"Here's a summary\", only write the content.\n",
    "#     \"\"\"\n",
    "# )\n",
    "# print(summarize_lyrics2['response'])\n",
    "\n",
    "# summarize_selection = ollama.generate(\n",
    "#     model=\"llama3.1\",\n",
    "#     # prompt=f\"This is the prompt from the user: {data}. Respond using this information: {json.dumps(data_from_db)}. Only use the book from the database to answer.\",\n",
    "#     prompt=f\"\"\"\n",
    "#     This is the user question: {prompt}\n",
    "\n",
    "#     This is the meta data information from the song '{results[\"metadatas\"][0][0][\"track_name\"]}': {json.dumps(results[\"metadatas\"][0][0])}\n",
    "    \n",
    "#     This is the lyrics of the song '{results[\"metadatas\"][0][0][\"track_name\"]}: {results[\"documents\"][0][0]}\n",
    "\n",
    "\n",
    "#     This is the meta data information of the song '{results[\"metadatas\"][0][1][\"track_name\"]}: {json.dumps(results[\"metadatas\"][0][1])}\n",
    "\n",
    "#     This is the lyrics of the song '{results[\"metadatas\"][0][1][\"track_name\"]}: {results[\"documents\"][0][1]}\n",
    "\n",
    "#     Answer the user question by selecting either information from '{results[\"metadatas\"][0][0][\"track_name\"]}' or '{results[\"metadatas\"][0][1][\"track_name\"]}' that are more closely relate to the user question. Why you select this song? \n",
    "#     If you think that both song are not related to user question. You must say that there is no song in the database that match the user description. \n",
    "#     Do not make up information. Do not mention the another song in the output. Do not use the sentence that means 'Based on the user's question' when answer. Do not mention the word that means summary.\n",
    "#     \"\"\"\n",
    "# )\n",
    "# print(\"__________________\")\n",
    "# print(summarize_selection['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Close the cursor and connection\n",
    "# cur.close()\n",
    "# conn.close()\n",
    "\n",
    "# print(\"Data inserted successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
